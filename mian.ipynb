{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjy4399/echomimic_v2/blob/main/mian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-ZgupbPwswS",
        "outputId": "d455e542-049b-4643-bee4-81e637dc0f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'echomimic_v2' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "  !git clone https://github.com/antgroup/echomimic_v2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 查询当前工作目录\n",
        "current_directory = os.getcwd()\n",
        "print(\"当前工作目录:\", current_directory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pkV1rsBxzdQ",
        "outputId": "e22ad87a-f558-4afb-a3d0-e473ba9c462e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "当前工作目录: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 更改工作目录\n",
        "os.chdir('/content/echomimic_v2')\n",
        "\n",
        "# 验证当前工作目录\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmWK-sinzLU3",
        "outputId": "502b1a48-02cf-4133-9797-ecdbf3cd2e4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/echomimic_v2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pip -U\n",
        "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 xformers==0.0.28.post3 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install torchao --index-url https://download.pytorch.org/whl/nightly/cu124\n",
        "!pip install -r requirements.txt\n",
        "!pip install --no-deps facenet_pytorch==2.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVoTma7ex8Ai",
        "outputId": "f4bc98cd-9610-4acf-b56a-590d998fc597"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.3.1)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision==0.20.1 in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio==2.5.1 in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: xformers==0.0.28.post3 in /usr/local/lib/python3.10/dist-packages (0.0.28.post3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.20.1) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.20.1) (11.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1) (2.1.5)\n",
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cu124\n",
            "Requirement already satisfied: torchao in /usr/local/lib/python3.10/dist-packages (0.8.0.dev20241219+cu124)\n",
            "Collecting clip@ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip#sha256=b5842c25da441d6c581b53a5c60e0c2127ebafe0f746f8e15561a006c6c3be6a (from -r requirements.txt (line 12))\n",
            "  Using cached https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip (4.3 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers>=4.46.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.47.0)\n",
            "Requirement already satisfied: diffusers==0.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.31.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.6.0)\n",
            "Requirement already satisfied: torchtyping in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: einops==0.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.8.0)\n",
            "Requirement already satisfied: omegaconf==2.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.10.0.84)\n",
            "Requirement already satisfied: av==13.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (13.1.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.6.0)\n",
            "Requirement already satisfied: accelerate==1.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: decord==0.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.6.0)\n",
            "Requirement already satisfied: gradio_client==1.4.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (1.4.3)\n",
            "Requirement already satisfied: imageio==2.36.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.36.0)\n",
            "Requirement already satisfied: imageio-ffmpeg==0.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (0.5.1)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (1.26.4)\n",
            "Requirement already satisfied: onnxruntime-gpu==1.20.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (1.20.1)\n",
            "Requirement already satisfied: open-clip-torch==2.29.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (2.29.0)\n",
            "Requirement already satisfied: opencv-contrib-python==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (11.0.0)\n",
            "Requirement already satisfied: scikit-image==0.24.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (0.24.0)\n",
            "Requirement already satisfied: scikit-learn==1.5.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (1.5.2)\n",
            "Requirement already satisfied: scipy==1.14.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (1.14.1)\n",
            "Requirement already satisfied: torchdiffeq==0.2.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (0.2.5)\n",
            "Requirement already satisfied: torchsde==0.2.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.2.6)\n",
            "Requirement already satisfied: mlflow==2.18.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (2.18.0)\n",
            "Requirement already satisfied: controlnet-aux==0.0.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 30)) (0.0.9)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (0.2.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (0.12.1)\n",
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (0.10.20)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (7.34.0)\n",
            "Requirement already satisfied: scenedetect in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 36)) (0.6.5.1)\n",
            "Requirement already satisfied: moviepy==1.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 37)) (1.0.3)\n",
            "Requirement already satisfied: huggingface_hub==0.26.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 38)) (0.26.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0->-r requirements.txt (line 2)) (8.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0->-r requirements.txt (line 2)) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0->-r requirements.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0->-r requirements.txt (line 2)) (0.4.5)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.3.0->-r requirements.txt (line 7)) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.3.0->-r requirements.txt (line 7)) (6.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.1.1->-r requirements.txt (line 11)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==1.1.1->-r requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.1.1->-r requirements.txt (line 11)) (2.5.1+cu121)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio_client==1.4.3->-r requirements.txt (line 16)) (2024.10.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio_client==1.4.3->-r requirements.txt (line 16)) (0.28.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio_client==1.4.3->-r requirements.txt (line 16)) (4.12.2)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio_client==1.4.3->-r requirements.txt (line 16)) (12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg==0.5.1->-r requirements.txt (line 18)) (75.1.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu==1.20.1->-r requirements.txt (line 20)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu==1.20.1->-r requirements.txt (line 20)) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu==1.20.1->-r requirements.txt (line 20)) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu==1.20.1->-r requirements.txt (line 20)) (1.13.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open-clip-torch==2.29.0->-r requirements.txt (line 21)) (0.20.1+cu121)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from open-clip-torch==2.29.0->-r requirements.txt (line 21)) (6.3.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open-clip-torch==2.29.0->-r requirements.txt (line 21)) (0.6.7)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.24.0->-r requirements.txt (line 24)) (3.4.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.24.0->-r requirements.txt (line 24)) (2024.12.12)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.24.0->-r requirements.txt (line 24)) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.2->-r requirements.txt (line 25)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.2->-r requirements.txt (line 25)) (3.5.0)\n",
            "Requirement already satisfied: trampoline>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from torchsde==0.2.6->-r requirements.txt (line 28)) (0.1.2)\n",
            "Requirement already satisfied: mlflow-skinny==2.18.0 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.18.0->-r requirements.txt (line 29)) (2.18.0)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.18.0->-r requirements.txt (line 29)) (3.1.0)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.18.0->-r requirements.txt (line 29)) (1.14.0)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.18.0->-r requirements.txt (line 29)) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.18.0->-r requirements.txt (line 29)) (3.4.3)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.18.0->-r requirements.txt (line 29)) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.18.0->-r requirements.txt (line 29)) (3.8.0)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.18.0->-r requirements.txt (line 29)) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<19,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.18.0->-r requirements.txt (line 29)) (17.0.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.18.0->-r requirements.txt (line 29)) (2.0.36)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.18.0->-r requirements.txt (line 29)) (3.1.4)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.18.0->-r requirements.txt (line 29)) (23.0.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from controlnet-aux==0.0.9->-r requirements.txt (line 30)) (4.10.0.84)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.3->-r requirements.txt (line 37)) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.3->-r requirements.txt (line 37)) (0.1.10)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (3.1.0)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (0.39.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (3.1.43)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (1.29.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (0.5.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.3->-r requirements.txt (line 1)) (0.21.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics->-r requirements.txt (line 3)) (0.11.9)\n",
            "Requirement already satisfied: typeguard<3,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from torchtyping->-r requirements.txt (line 4)) (2.13.3)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (0.4.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (3.10.12)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (2.10.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart==0.0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (0.0.12)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (0.8.3)\n",
            "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (0.41.3)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (0.15.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 10)) (0.34.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python->-r requirements.txt (line 31)) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->-r requirements.txt (line 32)) (1.17.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe->-r requirements.txt (line 33)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe->-r requirements.txt (line 33)) (24.3.0)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe->-r requirements.txt (line 33)) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe->-r requirements.txt (line 33)) (0.4.33)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe->-r requirements.txt (line 33)) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe->-r requirements.txt (line 33)) (0.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython->-r requirements.txt (line 35)) (0.19.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->-r requirements.txt (line 35)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->-r requirements.txt (line 35)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->-r requirements.txt (line 35)) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->-r requirements.txt (line 35)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->-r requirements.txt (line 35)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->-r requirements.txt (line 35)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->-r requirements.txt (line 35)) (4.9.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from scenedetect->-r requirements.txt (line 36)) (4.3.6)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow==2.18.0->-r requirements.txt (line 29)) (1.3.8)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 10)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 10)) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 32)) (2.22)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow==2.18.0->-r requirements.txt (line 29)) (2.2.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow==2.18.0->-r requirements.txt (line 29)) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow==2.18.0->-r requirements.txt (line 29)) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow==2.18.0->-r requirements.txt (line 29)) (1.9.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow==2.18.0->-r requirements.txt (line 29)) (3.2.5)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow==2.18.0->-r requirements.txt (line 29)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow==2.18.0->-r requirements.txt (line 29)) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client==1.4.3->-r requirements.txt (line 16)) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client==1.4.3->-r requirements.txt (line 16)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio_client==1.4.3->-r requirements.txt (line 16)) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.31.0->-r requirements.txt (line 2)) (3.21.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->-r requirements.txt (line 35)) (0.8.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow==2.18.0->-r requirements.txt (line 29)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow==2.18.0->-r requirements.txt (line 29)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow==2.18.0->-r requirements.txt (line 29)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow==2.18.0->-r requirements.txt (line 29)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow==2.18.0->-r requirements.txt (line 29)) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow==2.18.0->-r requirements.txt (line 29)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow==2.18.0->-r requirements.txt (line 29)) (2024.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->-r requirements.txt (line 35)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->-r requirements.txt (line 35)) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 10)) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.31.0->-r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.18.0->-r requirements.txt (line 29)) (3.1.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu==1.20.1->-r requirements.txt (line 20)) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 10)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 10)) (13.9.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime-gpu==1.20.1->-r requirements.txt (line 20)) (10.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe->-r requirements.txt (line 33)) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe->-r requirements.txt (line 33)) (3.4.0)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (4.0.11)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (1.2.15)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (0.50b0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow==2.18.0->-r requirements.txt (line 29)) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 10)) (3.0.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (1.17.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (4.9)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 10)) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 29)) (0.6.1)\n",
            "Requirement already satisfied: facenet_pytorch==2.6.0 in /usr/local/lib/python3.10/dist-packages (2.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import tarfile\n",
        "\n",
        "# 文件的下载链接\n",
        "url = \"https://www.johnvansickle.com/ffmpeg/old-releases/ffmpeg-4.4-amd64-static.tar.xz\"\n",
        "# 本地文件名\n",
        "file_name = \"ffmpeg-4.4-amd64-static.tar.xz\"\n",
        "\n",
        "# 下载文件\n",
        "response = requests.get(url)\n",
        "with open(file_name, 'wb') as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "print(f\"下载完成: {file_name}\")\n",
        "\n",
        "# 解压文件\n",
        "with tarfile.open(file_name, 'r:xz') as tar:\n",
        "    tar.extractall(path=\"./ffmpeg\")  # 解压到当前目录下的 ffmpeg 文件夹\n",
        "\n",
        "print(\"解压完成，文件已保存到 ./ffmpeg 目录。\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LiwQA0tzzX0",
        "outputId": "7146727f-2196-4ef5-b71a-9f6931e68dca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "下载完成: ffmpeg-4.4-amd64-static.tar.xz\n",
            "解压完成，文件已保存到 ./ffmpeg 目录。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# 文件 URL\n",
        "url = \"https://openaipublic.azureedge.net/main/whisper/models/65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt\"\n",
        "# 指定下载目录\n",
        "download_directory = \"./pretrained_weights/audio_processor\"\n",
        "# 文件名\n",
        "file_name = os.path.join(download_directory, \"tiny.pt\")\n",
        "\n",
        "# 创建目录（如果不存在）\n",
        "os.makedirs(download_directory, exist_ok=True)\n",
        "\n",
        "# 下载文件\n",
        "response = requests.get(url)\n",
        "\n",
        "# 检查请求是否成功\n",
        "if response.status_code == 200:\n",
        "    with open(file_name, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f\"文件已成功下载到 {file_name}\")\n",
        "else:\n",
        "    print(\"下载失败，状态码:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVWUdIW39Jv9",
        "outputId": "f6abe4c5-ee48-45dc-d08f-d55e8ca77e6d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "文件已成功下载到 ./pretrained_weights/audio_processor/tiny.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export FFMPEG_PATH=/content/echomimic_v2/ffmpeg/ffmpeg-4.4-amd64-static"
      ],
      "metadata": {
        "id": "s9BPUCrPzh8q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/BadToBest/EchoMimicV2 pretrained_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRI-emXB2o3r",
        "outputId": "bb483af6-7f2f-4050-dea8-a2a41a347449"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'pretrained_weights'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 34 (delta 13), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (34/34), 14.73 KiB | 1.47 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 5.53 GiB | 46.72 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/lambdalabs/sd-image-variations-diffusers pretrained_weights/sd-image-variations-diffusers"
      ],
      "metadata": {
        "id": "hKpvSv2A_S38",
        "outputId": "b6e06089-e55a-4a00-b23c-4e7fa47d80dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pretrained_weights/sd-image-variations-diffusers'...\n",
            "remote: Enumerating objects: 98, done.\u001b[K\n",
            "remote: Total 98 (delta 0), reused 0 (delta 0), pack-reused 98 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (98/98), 1.57 MiB | 5.24 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 5.77 GiB | 40.30 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ghifM4Z3Os-",
        "outputId": "74d92afe-d437-4ed5-a4ee-4fc0ad357b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-19 08:24:38.684268: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-19 08:24:38.717557: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-19 08:24:38.727609: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-19 08:24:40.788808: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "import error: No module named 'triton'\n",
            "\u001b[32mCUDA版本：12.1\u001b[0m\n",
            "\u001b[32mPytorch版本：2.5.1+cu121\u001b[0m\n",
            "\u001b[32m显卡型号：Tesla T4\u001b[0m\n",
            "\u001b[32m显存大小：14.75GB\u001b[0m\n",
            "\u001b[32m精度：float16\u001b[0m\n",
            "please download ffmpeg-static and export to FFMPEG_PATH. \n",
            "For example: export FFMPEG_PATH=./ffmpeg-4.4-amd64-static\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://0eb16417f1f0cd8ce4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "Some weights of the model checkpoint were not used when initializing UNet2DConditionModel: \n",
            " ['down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.0.attentions.0.transformer_blocks.0.norm2.weight, down_blocks.0.attentions.0.transformer_blocks.0.norm2.bias, down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.0.attentions.1.transformer_blocks.0.norm2.weight, down_blocks.0.attentions.1.transformer_blocks.0.norm2.bias, down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight, down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias, down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight, down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias, down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight, down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias, down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight, down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias, up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight, up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias, up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight, up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias, up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight, up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias, up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.2.attentions.0.transformer_blocks.0.norm2.weight, up_blocks.2.attentions.0.transformer_blocks.0.norm2.bias, up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.2.attentions.1.transformer_blocks.0.norm2.weight, up_blocks.2.attentions.1.transformer_blocks.0.norm2.bias, up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_q.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_k.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_v.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.2.attentions.2.transformer_blocks.0.norm2.weight, up_blocks.2.attentions.2.transformer_blocks.0.norm2.bias, up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_q.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_k.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_v.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.3.attentions.0.transformer_blocks.0.norm2.weight, up_blocks.3.attentions.0.transformer_blocks.0.norm2.bias, up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_q.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_k.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_v.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.3.attentions.1.transformer_blocks.0.norm2.weight, up_blocks.3.attentions.1.transformer_blocks.0.norm2.bias, up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_k.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.3.attentions.2.transformer_blocks.0.norm2.weight, up_blocks.3.attentions.2.transformer_blocks.0.norm2.bias, mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight, mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight, mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight, mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, mid_block.attentions.0.transformer_blocks.0.norm2.weight, mid_block.attentions.0.transformer_blocks.0.norm2.bias, conv_norm_out.weight, conv_norm_out.bias, conv_out.weight, conv_out.bias']\n",
            "using motion module\n",
            "WARNING:py.warnings:/content/echomimic_v2/src/models/whisper/whisper/__init__.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "\n",
            "Pose: assets/halfbody_demo/pose/01\n",
            "Reference: /tmp/gradio/d3c6c8421a56dac65c0a8d57d5fbdf80061095b7e0484d41bbc75f5a9d197a66/0001.png\n",
            "Audio: /tmp/gradio/6b74fa98a7a324aba59de99b73d4966a50d5916e769e84af934ffeb7a575e6ec/echomimicv2_man.wav\n",
            "video in 24 FPS, audio idx in 50FPS\n",
            "WARNING:py.warnings:/content/echomimic_v2/src/pipelines/pipeline_echomimicv2.py:476: FutureWarning: Accessing config attribute `in_channels` directly via 'EMOUNet3DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'EMOUNet3DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
            "  num_channels_latents = self.denoising_unet.in_channels\n",
            "\n",
            "latents shape:torch.Size([1, 4, 125, 96, 96]), video_length:125\n",
            "  0% 0/20 [00:00<?, ?it/s]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/diffusers/models/resnet.py:323: FutureWarning: `scale` is deprecated and will be removed in version 1.0.0. The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`.\n",
            "  deprecate(\"scale\", \"1.0.0\", deprecation_message)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/diffusers/models/downsampling.py:135: FutureWarning: `scale` is deprecated and will be removed in version 1.0.0. The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`.\n",
            "  deprecate(\"scale\", \"1.0.0\", deprecation_message)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/diffusers/models/upsampling.py:145: FutureWarning: `scale` is deprecated and will be removed in version 1.0.0. The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`.\n",
            "  deprecate(\"scale\", \"1.0.0\", deprecation_message)\n",
            "\n",
            " 15% 3/20 [07:00<39:46, 140.35s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "refimg_path = './assets/halfbody_demo/refimag/test.png'\n",
        "audio_path ='./assets/halfbody_demo/audio/chinese/echomimicv2_woman.wav'\n",
        "using_video_driving = False\n",
        "if not using_video_driving:\n",
        "  pose_path = './assets/halfbody_demo/pose/good'"
      ],
      "metadata": {
        "id": "rei58cS85NJl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reference image aligned\n",
        "import sys\n",
        "from src.utils.img_utils import pil_to_cv2, cv2_to_pil, center_crop_cv2, pils_from_video, save_videos_from_pils, save_video_from_cv2_list\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from IPython import embed\n",
        "import numpy as np\n",
        "import copy\n",
        "from src.utils.motion_utils import motion_sync\n",
        "import pathlib\n",
        "import torch\n",
        "import pickle\n",
        "from glob import glob\n",
        "import os\n",
        "from src.models.dwpose.dwpose_detector import dwpose_detector as dwprocessor\n",
        "from src.models.dwpose.util import draw_pose\n",
        "import decord\n",
        "from tqdm import tqdm\n",
        "from moviepy.editor import AudioFileClip, VideoFileClip\n",
        "from multiprocessing.pool import ThreadPool\n",
        "\n",
        "##################################\n",
        "process_num = 100 #1266\n",
        "\n",
        "start = 0\n",
        "end = process_num + start\n",
        "#################################\n",
        "MAX_SIZE = 768\n",
        "\n",
        "def convert_fps(src_path, tgt_path, tgt_fps=24, tgt_sr=16000):\n",
        "    clip = VideoFileClip(src_path)\n",
        "    new_clip = clip.set_fps(tgt_fps)\n",
        "    if tgt_fps is not None:\n",
        "        audio = new_clip.audio\n",
        "        audio = audio.set_fps(tgt_sr)\n",
        "        new_clip = new_clip.set_audio(audio)\n",
        "    if '.mov' in tgt_path:\n",
        "        tgt_path = tgt_path.replace('.mov', '.mp4')\n",
        "    new_clip.write_videofile(tgt_path, codec='libx264', audio_codec='aac')\n",
        "\n",
        "def get_video_pose(\n",
        "        video_path: str,\n",
        "        sample_stride: int=1,\n",
        "        max_frame=None):\n",
        "\n",
        "    # read input video\n",
        "    vr = decord.VideoReader(video_path, ctx=decord.cpu(0))\n",
        "    sample_stride *= max(1, int(vr.get_avg_fps() / 24))\n",
        "\n",
        "    frames = vr.get_batch(list(range(0, len(vr), sample_stride))).asnumpy()\n",
        "    # print(frames[0])\n",
        "    if max_frame is not None:\n",
        "        frames = frames[0:max_frame,:,:]\n",
        "    height, width, _ = frames[0].shape\n",
        "    detected_poses = [dwprocessor(frm) for frm in frames]\n",
        "    dwprocessor.release_memory()\n",
        "\n",
        "    return detected_poses, height, width, frames\n",
        "\n",
        "def resize_and_pad(img, max_size):\n",
        "    img_new = np.zeros((max_size, max_size, 3)).astype('uint8')\n",
        "    imh, imw = img.shape[0], img.shape[1]\n",
        "    half = max_size // 2\n",
        "    if imh > imw:\n",
        "        imh_new = max_size\n",
        "        imw_new = int(round(imw/imh * imh_new))\n",
        "        half_w = imw_new // 2\n",
        "        rb, re = 0, max_size\n",
        "        cb = half-half_w\n",
        "        ce = cb + imw_new\n",
        "    else:\n",
        "        imw_new = max_size\n",
        "        imh_new = int(round(imh/imw * imw_new))\n",
        "        half_h = imh_new // 2\n",
        "        cb, ce = 0, max_size\n",
        "        rb = half-half_h\n",
        "        re = rb + imh_new\n",
        "\n",
        "    img_resize = cv2.resize(img, (imw_new, imh_new))\n",
        "    img_new[rb:re,cb:ce,:] = img_resize\n",
        "    return img_new\n",
        "\n",
        "def resize_and_pad_param(imh, imw, max_size):\n",
        "    half = max_size // 2\n",
        "    if imh > imw:\n",
        "        imh_new = max_size\n",
        "        imw_new = int(round(imw/imh * imh_new))\n",
        "        half_w = imw_new // 2\n",
        "        rb, re = 0, max_size\n",
        "        cb = half-half_w\n",
        "        ce = cb + imw_new\n",
        "    else:\n",
        "        imw_new = max_size\n",
        "        imh_new = int(round(imh/imw * imw_new))\n",
        "        imh_new = max_size\n",
        "\n",
        "        half_h = imh_new // 2\n",
        "        cb, ce = 0, max_size\n",
        "        rb = half-half_h\n",
        "        re = rb + imh_new\n",
        "\n",
        "    return imh_new, imw_new, rb, re, cb, ce\n",
        "\n",
        "def get_pose_params(detected_poses, max_size):\n",
        "    print('get_pose_params...')\n",
        "    # pose rescale\n",
        "    w_min_all, w_max_all, h_min_all, h_max_all = [], [], [], []\n",
        "    mid_all = []\n",
        "    for num, detected_pose in enumerate(detected_poses):\n",
        "        detected_poses[num]['num'] = num\n",
        "        candidate_body = detected_pose['bodies']['candidate']\n",
        "        score_body = detected_pose['bodies']['score']\n",
        "        candidate_face = detected_pose['faces']\n",
        "        score_face = detected_pose['faces_score']\n",
        "        candidate_hand = detected_pose['hands']\n",
        "        score_hand = detected_pose['hands_score']\n",
        "\n",
        "        # face\n",
        "        if candidate_face.shape[0] > 1:\n",
        "            index = 0\n",
        "            candidate_face = candidate_face[index]\n",
        "            score_face = score_face[index]\n",
        "            detected_poses[num]['faces'] = candidate_face.reshape(1, candidate_face.shape[0], candidate_face.shape[1])\n",
        "            detected_poses[num]['faces_score'] = score_face.reshape(1, score_face.shape[0])\n",
        "        else:\n",
        "            candidate_face = candidate_face[0]\n",
        "            score_face = score_face[0]\n",
        "\n",
        "        # body\n",
        "        if score_body.shape[0] > 1:\n",
        "            tmp_score = []\n",
        "            for k in range(0, score_body.shape[0]):\n",
        "                tmp_score.append(score_body[k].mean())\n",
        "            index = np.argmax(tmp_score)\n",
        "            candidate_body = candidate_body[index*18:(index+1)*18,:]\n",
        "            score_body = score_body[index]\n",
        "            score_hand = score_hand[(index*2):(index*2+2),:]\n",
        "            candidate_hand = candidate_hand[(index*2):(index*2+2),:,:]\n",
        "        else:\n",
        "            score_body = score_body[0]\n",
        "        all_pose = np.concatenate((candidate_body, candidate_face))\n",
        "        all_score = np.concatenate((score_body, score_face))\n",
        "        all_pose = all_pose[all_score>0.8]\n",
        "\n",
        "        body_pose = np.concatenate((candidate_body,))\n",
        "        mid_ = body_pose[1, 0]\n",
        "\n",
        "        face_pose = candidate_face\n",
        "        hand_pose = candidate_hand\n",
        "\n",
        "        h_min, h_max = np.min(face_pose[:,1]), np.max(body_pose[:7,1])\n",
        "\n",
        "        h_ = h_max - h_min\n",
        "\n",
        "        mid_w = mid_\n",
        "        w_min = mid_w - h_ // 2\n",
        "        w_max = mid_w + h_ // 2\n",
        "\n",
        "        w_min_all.append(w_min)\n",
        "        w_max_all.append(w_max)\n",
        "        h_min_all.append(h_min)\n",
        "        h_max_all.append(h_max)\n",
        "        mid_all.append(mid_w)\n",
        "\n",
        "    w_min = np.min(w_min_all)\n",
        "    w_max = np.max(w_max_all)\n",
        "    h_min = np.min(h_min_all)\n",
        "    h_max = np.max(h_max_all)\n",
        "    mid = np.mean(mid_all)\n",
        "\n",
        "    margin_ratio = 0.25\n",
        "    h_margin = (h_max-h_min)*margin_ratio\n",
        "\n",
        "    h_min = max(h_min-h_margin*0.8, 0)\n",
        "    h_max = min(h_max+h_margin*0.1, 1)\n",
        "\n",
        "    h_new = h_max - h_min\n",
        "\n",
        "    h_min_real = int(h_min*height)\n",
        "    h_max_real = int(h_max*height)\n",
        "    mid_real = int(mid*width)\n",
        "\n",
        "    height_new = h_max_real-h_min_real+1\n",
        "    width_new = height_new\n",
        "    w_min_real = mid_real - width_new // 2\n",
        "    if w_min_real < 0:\n",
        "      w_min_real = 0\n",
        "      width_new = mid_real * 2\n",
        "\n",
        "    w_max_real = w_min_real + width_new\n",
        "    w_min = w_min_real / width\n",
        "    w_max = w_max_real / width\n",
        "\n",
        "    imh_new, imw_new, rb, re, cb, ce = resize_and_pad_param(height_new, width_new, max_size)\n",
        "    res = {'draw_pose_params': [imh_new, imw_new, rb, re, cb, ce],\n",
        "           'pose_params': [w_min, w_max, h_min, h_max],\n",
        "           'video_params': [h_min_real, h_max_real, w_min_real, w_max_real],\n",
        "           }\n",
        "    return res\n",
        "\n",
        "def save_pose_params_item(input_items):\n",
        "    detected_pose, pose_params, draw_pose_params, save_dir = input_items\n",
        "    w_min, w_max, h_min, h_max = pose_params\n",
        "    num = detected_pose['num']\n",
        "    candidate_body = detected_pose['bodies']['candidate']\n",
        "    candidate_face = detected_pose['faces'][0]\n",
        "    candidate_hand = detected_pose['hands']\n",
        "    candidate_body[:,0] = (candidate_body[:,0]-w_min)/(w_max-w_min)\n",
        "    candidate_body[:,1] = (candidate_body[:,1]-h_min)/(h_max-h_min)\n",
        "    candidate_face[:,0] = (candidate_face[:,0]-w_min)/(w_max-w_min)\n",
        "    candidate_face[:,1] = (candidate_face[:,1]-h_min)/(h_max-h_min)\n",
        "    candidate_hand[:,:,0] = (candidate_hand[:,:,0]-w_min)/(w_max-w_min)\n",
        "    candidate_hand[:,:,1] = (candidate_hand[:,:,1]-h_min)/(h_max-h_min)\n",
        "    detected_pose['bodies']['candidate'] = candidate_body\n",
        "    detected_pose['faces'] = candidate_face.reshape(1, candidate_face.shape[0], candidate_face.shape[1])\n",
        "    detected_pose['hands'] = candidate_hand\n",
        "    detected_pose['draw_pose_params'] = draw_pose_params\n",
        "    np.save(save_dir+'/'+str(num)+'.npy', detected_pose)\n",
        "\n",
        "def save_pose_params(detected_poses, pose_params, draw_pose_params, ori_video_path):\n",
        "    save_dir = ori_video_path.replace('video', 'pose/')\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    input_list = []\n",
        "\n",
        "    for i, detected_pose in enumerate(detected_poses):\n",
        "        input_list.append([detected_pose, pose_params, draw_pose_params, save_dir])\n",
        "\n",
        "    pool = ThreadPool(8)\n",
        "    pool.map(save_pose_params_item, input_list)\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    return save_dir\n",
        "from torchvision.transforms import functional as F\n",
        "def get_img_pose(\n",
        "        img_path: str,\n",
        "        sample_stride: int=1,\n",
        "        max_frame=None):\n",
        "\n",
        "  # read input img\n",
        "  frame = cv2.imread(img_path)\n",
        "  height, width, _ = frame.shape\n",
        "  short_size = min(height, width)\n",
        "  resize_ratio = max(MAX_SIZE / short_size, 1.0)\n",
        "  frame = cv2.resize(frame, (int(resize_ratio * width), int(resize_ratio * height)))\n",
        "  height, width, _ = frame.shape\n",
        "  detected_poses = [dwprocessor(frame)]\n",
        "  dwprocessor.release_memory()\n",
        "\n",
        "  return detected_poses, height, width, frame\n",
        "\n",
        "def save_aligned_img(ori_frame, video_params, max_size):\n",
        "  h_min_real, h_max_real, w_min_real, w_max_real = video_params\n",
        "  img = ori_frame[h_min_real:h_max_real,w_min_real:w_max_real,:]\n",
        "  img_aligened = resize_and_pad(img, max_size=max_size)\n",
        "  print('aligned img shape:', img_aligened.shape)\n",
        "  save_dir = './assets/refimg_aligned'\n",
        "\n",
        "  os.makedirs(save_dir, exist_ok=True)\n",
        "  save_path = os.path.join(save_dir, 'aligned.png')\n",
        "  cv2.imwrite(save_path, img_aligened)\n",
        "  return save_path\n",
        "\n",
        "detected_poses, height, width, ori_frame = get_img_pose(refimg_path, max_frame=None)\n",
        "res_params = get_pose_params(detected_poses, MAX_SIZE)\n",
        "refimg_aligned_path = save_aligned_img(ori_frame, res_params['video_params'], MAX_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "Ar-hhPpE5Reg",
        "outputId": "08c9a683-c462-4383-b89b-1bfa393346c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dwpose_detector init ok cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NoSuchFile",
          "evalue": "[ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from your_path_to_yolox_l.onnx failed:Load model your_path_to_yolox_l.onnx failed. File doesn't exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNoSuchFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-cdb33ee60040>\u001b[0m in \u001b[0;36m<cell line: 265>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    263\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m \u001b[0mdetected_poses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mori_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_img_pose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0mres_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pose_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetected_poses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0mrefimg_aligned_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_aligned_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-cdb33ee60040>\u001b[0m in \u001b[0;36mget_img_pose\u001b[0;34m(img_path, sample_stride, max_frame)\u001b[0m\n\u001b[1;32m    246\u001b[0m   \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m   \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m   \u001b[0mdetected_poses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdwprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m   \u001b[0mdwprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/echomimic_v2/src/models/dwpose/dwpose_detector.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, oriImg)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pose_estimation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_estimation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWholebody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moriImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriImg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/echomimic_v2/src/models/dwpose/wholebody.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_det, model_pose, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprovider_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cpu'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'device_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         self.session_det = ort.InferenceSession(\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_det\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproviders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mprovider_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprovider_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_inference_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled_optimizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m_create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_config_from_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_config_from_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNoSuchFile\u001b[0m: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from your_path_to_yolox_l.onnx failed:Load model your_path_to_yolox_l.onnx failed. File doesn't exist"
          ]
        }
      ]
    }
  ]
}